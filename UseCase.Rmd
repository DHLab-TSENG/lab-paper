---
title: "A use case in lab package paper"
author: Yi-Ju Tseng, Chun Ju Chen
output: github_document
---
*lab*: An R package for generating analysis-ready data from laboratory records

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r install, eval=F}
remotes::install_github("DHLab-TSENG/lab")
remotes::install_github("DHLab-TSENG/dxpr")
```

```{r lib}
library(dxpr)
library(lab)
library(dplyr)
library(data.table)
```

```{r data}
load("newborn/newborn_ICD.rda")
```

# Case Identification (with dxpr package)
```{r selectCases}
Case <- selectCases(dxDataFile = newborn_ICD,
                    idColName = SUBJECT_ID,
                    icdColName = ICD9_CODE,
                    dateColName = ADMITTIME,
                    icd10usingDate = "9999/01/01",
                    groupDataType = ICD,
                    caseCondition = "^7470",
                    caseCount = 1,
                    caseName = "PDA")
table(Case$selectedCase)
PDA<-Case[selectedCase=="PDA"]
```
```{r eval=F}
head(PDA)
```
```{r echo=F}
knitr::kable(head(PDA))
```


# Load Laboratory Records of Cases and Controls
Load laboratory records. Data is not included due to the terms of use. Please check [Medical Information Mart for Intensive Care](https://mimic.mit.edu/) for more information.
```{r labdata}
if(file.exists("newborn/PDALab.rds")){
  PDALab<-readRDS("newborn/PDALab.rds")
}else{
  LABEVENTS <- fread("newborn/LABEVENTS.csv")
  PDALab<-LABEVENTS[SUBJECT_ID %in% PDA$ID]
  PDALab<-PDALab %>% select(-ROW_ID,-HADM_ID)
  saveRDS(PDALab,"newborn/PDALab.rds")
}
LONICMap<-fread("newborn/D_LABITEMS.csv")
LONICMap<-LONICMap %>% select(-ROW_ID)
Patients<-fread("newborn/PATIENTS.csv")
PDAPatients<-Patients[SUBJECT_ID %in% PDA$ID]
saveRDS(PDAPatients,"newborn/PDAPatients.rds")
Patients<-Patients %>% select(-ROW_ID)

PDA<-inner_join(PDA,Patients,by=c("ID"="SUBJECT_ID"))
PDA$DeathDay<-difftime(PDA$DOD_HOSP,PDA$firstCaseDate,units = "days")
PDA$D30<-ifelse(PDA$DeathDay<=30,"Y","N")
PDA$D30<-ifelse(is.na(PDA$D30),"N",PDA$D30)
```

Select laboratory tests which were given to more than 95% of individuals in the study population.
```{r lab-filter}
PDAItem95<-
  PDALab %>% group_by(ITEMID) %>%
  summarise(Ind=n_distinct(SUBJECT_ID),
            Total=length(unique(PDALab$SUBJECT_ID)),
            Perc=Ind/Total) %>%
  arrange(desc(Perc)) %>%
  filter(Perc>0.95)
PDALab95<-PDALab %>% filter(ITEMID %in% PDAItem95$ITEMID)
```
```{r eval=F}
head(PDALab95)
```
```{r echo=F}
knitr::kable(head(PDALab95))
```

# LONIC Mapping

Map laboratory item code (ITEMID) with LOINC. The mapping table `LONICMap` is provided by [MIMIC](https://mimic.mit.edu/)
```{r lonic-map}
PDALabLONIC <- mapLOINC(labData = PDALab95, 
                        labItemColName = ITEMID, 
                        mappingTable = LONICMap)
```

```{r eval=F}
head(PDALabLONIC)
```
```{r echo=F}
knitr::kable(head(PDALabLONIC))
```

## Normal or Abnormal Test Results Identificaiton
Use reference range information `refLOINC` provided by LONIC to identify normal and abnormal test results.
The `Patients` table is used to provide gender information because reference ranges are different across gender.
```{r Ab}
if(!"LOINC_CODE" %in% colnames(refLOINC)){
  refLOINC<-rename(refLOINC,LOINC_CODE=LOINC)
}
PDALabLONIC_ab <- getAbnormalMark(labData = PDALabLONIC,
                                  idColName = SUBJECT_ID,
                                  labItemColName = LOINC_CODE,
                                  valueColName = VALUENUM,
                                  genderColName = GENDER,
                                  genderTable = Patients,
                                  referenceTable = refLOINC)
```

```{r eval=F}
head(PDALabLONIC_ab)
```
```{r echo=F}
knitr::kable(head(PDALabLONIC_ab))
```

# Time Series Analysis

## Deciding Width of Windows for Slicing Data
Then we need to decide a proper width of window for slicing laboratory records into time-series window.
`plotWindowProportion` helps users explore the proportion of missing values in each slicing window. 
```{r window, fig.width=7}
PDAIndex<-PDA[,c("ID","firstCaseDate")]
colnames(PDAIndex)<-c("ID","indexDate")
windowProportion <- plotWindowProportion(labData = PDALabLONIC,
                                         idColName = SUBJECT_ID,
                                         labItemColName = LABEL,
                                         dateColName = CHARTTIME,
                                         indexDate = PDAIndex,
                                         gapDate = c(1, 3, 7, 14),
                                         studyPeriodStartDays=0,
                                         studyPeriodEndDays=31)

print(windowProportion$graph)
ggplot2::ggsave("windowplot.pdf",dev="pdf",width=9,height=7)
```


The figure shows that using 1 or 3 days window may generate large amount of missing records and it could affect the analysis results,.
```{r eval=F}
head(windowProportion$missingData)
```
```{r echo=F}
knitr::kable(head(windowProportion$missingData))
```

## Slice the Data into Time-series Window

Based on the above figure, we choose 7-day window in this analysis.
```{r time-series}
timeSeriesData <- getTimeSeriesLab(labData = PDALabLONIC,
                                   idColName = SUBJECT_ID,
                                   labItemColName = LOINC_CODE + LABEL,
                                   dateColName = CHARTTIME,
                                   valueColName = VALUENUM,
                                   indexDate = PDAIndex,
                                   gapDate = 7,
                                   completeWindows = TRUE)

```

```{r eval=F}
head(timeSeriesData)
```
```{r echo=F}
knitr::kable(head(timeSeriesData))
```

## Time-series Window Visualization
For some individuals which need further data exploration, users can visualize the time series data. We randomly choose 5 individuals in this use case, and found that 
```{r time-series-plot, fig.width=7}
timeSeriesDataInd<-timeSeriesData %>% 
  filter(ID %in% c(93,126))
timeSeriesPlot <- plotTimeSeriesLab(labData = timeSeriesDataInd,
                                    idColName = ID,
                                    labItemColName = LOINC_CODE + LABEL,
                                    timeMarkColName = Window,
                                    valueColName = Nearest,
                                    timeStart = 1,
                                    timeEnd  = 10,
                                    abnormalMarkColName = NULL)

plot(timeSeriesPlot)
ggplot2::ggsave("timeplot.pdf",dev="pdf",width=8,height=6)
```

## Analysis Ready Data Generation
```{r ADR}
WideTimeSeriesData <- wideTimeSeriesLab(labData = timeSeriesData,
                                        idColName = ID,
                                        labItemColName = LOINC_CODE+ LABEL,
                                        windowColName = Window,
                                        valueColName = Nearest)
```

```{r eval=F}
head(WideTimeSeriesData)
```
```{r echo=F}
knitr::kable(head(WideTimeSeriesData))
```

## Compare Laboratory Results based on 30-day in-hospital mortality
```{r PDA analysis}
PDAandLab<-
  inner_join(PDA,WideTimeSeriesData,by="ID")
var<-colnames(PDAandLab)[20:34]
var
```

We can compare laboratory results in selected window (for example, 1) between with and without 30-day in-hospital mortality groups. As the table shown, some results were different between with and without 30-day in-hospital mortality groups. 
```{r tableone}
t1<-tableone::CreateTableOne(data=PDAandLab %>% filter(Window==1),
                             strata = c("D30"),
                             var=var)
```
```{r tablehide, results='hide'}
t1p<-print(t1)
write.csv(t1p,"t1p.csv")
```
```{r echo=F}
knitr::kable(t1p)
```

## Missing Value Imputation
If the data is prepared for model development, some missing values are not allowed in some machine learning algorithms. Users can impute the missing values with NOCB strategy (next observation carried backward) with `imputeTimeSeriesLab`.
```{r impute}
fullTimeSeriesData <- imputeTimeSeriesLab(labData = timeSeriesData,
                                          idColName = ID,
                                          labItemColName = LOINC_CODE + LABEL,
                                          windowColName = Window,
                                          valueColName = Mean & Nearest,
                                          impMethod = NOCB,
                                          imputeOverallMean = FALSE)
```
```{r eval=F}
head(fullTimeSeriesData)
```
```{r echo=F}
knitr::kable(head(fullTimeSeriesData))
```

After imputation, we can convert the records into wide format to generate the analysis read data.
```{r ADRFull}
FullWideTimeSeriesData <- wideTimeSeriesLab(labData = fullTimeSeriesData,
                                            idColName = ID,
                                            labItemColName = LOINC_CODE+ LABEL,
                                            windowColName = Window,
                                            valueColName = Nearest)
```

```{r eval=F}
head(FullWideTimeSeriesData)
```
```{r echo=F}
knitr::kable(head(FullWideTimeSeriesData))
```

## Deep Learning Model Development with Analysis Ready Data
Window =5
```{r LSTM}
FullPDALab<-
  inner_join(PDA,FullWideTimeSeriesData,by="ID")
FullPDALab<-FullPDALab %>% filter(ID!=72)
TrainData<-FullPDALab %>% 
  filter(Window>0&Window<=5) %>% select(ID,Window,18:34)
TrainDataFill <- TrainData %>%
  tidyr::complete(ID, Window)
TrainDataFill<-TrainDataFill%>%replace(is.na(.), 0)
TrainDataFill<-TrainDataFill %>% arrange(Window,ID)
pureTrain<-TrainDataFill %>% select(-ID,-Window)
nPatient<-length(unique(TrainDataFill$ID))
TrainArray<-array(unlist(pureTrain),
                  dim=c(nPatient,5,17))
TrainTarget<-FullPDALab %>% arrange(ID) %>% select(ID,D30) %>% 
  unique() %>% pull(D30)
TrainTarget<-array(ifelse(TrainTarget=="Y",1,0))
TrainTargetFinal<-
  array(rep(TrainTarget,5),
        dim=c(nPatient,5,1))
library(keras)

model <- keras_model_sequential()
model %>%
        layer_lstm(16, 
                   batch_input_shape = c(126, 5, 17),
                   return_sequences =TRUE, stateful= TRUE,
                   kernel_regularizer = regularizer_l2(0.001)) %>%
        layer_dropout(rate=0) %>%
        layer_dense(16,activation = 'relu') %>%
        layer_dense(1,activation = 'sigmoid')
model %>% compile(
      loss = 'binary_crossentropy',
      optimizer = 'adam',
      metrics= tensorflow::tf$keras$metrics$AUC())

fit<-model %>% fit(
      x = TrainArray,
      y = TrainTargetFinal,
      batch_size = 126,
      epoch= 100 ,
      verbose = 1,
      shuffle = FALSE
    )
plot(fit)
```
